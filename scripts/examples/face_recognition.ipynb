{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "face_recognition.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYvVEJ4QmOo5"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import time\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT8Tx0NymkhZ"
      },
      "source": [
        "!wget http://vis-www.cs.umass.edu/lfw/lfw.tgz\n",
        "!tar -xf lfw.tgz\n",
        "!rm lfw.tgz\n",
        "!wget https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKGsgojff3iI"
      },
      "source": [
        "people = os.listdir('lfw')\n",
        "pn_pairs = []\n",
        "for person in people:\n",
        "  temp = people.copy()\n",
        "  temp.pop(temp.index(person))\n",
        "  pn_pairs.append((person, random.choice(temp)))\n",
        "\n",
        "print(pn_pairs)\n",
        "assert len(pn_pairs) == len(people)\n",
        "assert all(x[0] != x[1] for x in pn_pairs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnJKKYHJoGNH"
      },
      "source": [
        "image_path = []\n",
        "for i in os.walk('lfw'):\n",
        "  for j in i[-1]:\n",
        "    image_path.append(i[0] + '/' + j)\n",
        "print(len(image_path))\n",
        "print(image_path[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhXw-1tghgTg"
      },
      "source": [
        "def make_pn_pairs(pairs=pn_pairs, dir='lfw'):\n",
        "  pn_images = []\n",
        "  for pair in pairs:\n",
        "    l = os.listdir(dir+'/'+pair[0]+'/')\n",
        "    for i in l:\n",
        "      image = dir+'/'+pair[0]+'/'+i\n",
        "      positive = dir+'/'+pair[0]+'/'+random.choice(l)\n",
        "      n = os.listdir(dir+'/'+pair[1]+'/')\n",
        "      negative = dir+'/'+pair[1]+'/'+random.choice(n)\n",
        "      pn_images.append((image, positive, negative))\n",
        "\n",
        "  return pn_images\n",
        "\n",
        "pn_images = make_pn_pairs()\n",
        "print(pn_images[0])\n",
        "assert all(((x[0].split('/')[1] == x[1].split('/')[1]) and (x[1] != x[2])) for x in pn_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm1lZa1MrX_n"
      },
      "source": [
        "Image.open(image_path[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFuqMIRUcwqM"
      },
      "source": [
        "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rkg9C37rYVf"
      },
      "source": [
        "def preprocess_image_pair(image_pair):\n",
        "  try:\n",
        "    img1, img2, img3 = tf.io.read_file(image_pair[0]), tf.io.read_file(image_pair[1]), tf.io.read_file(image_pair[2])\n",
        "    img1, img2, img3 = tf.image.decode_jpeg(img1, channels=3), tf.image.decode_jpeg(img2, channels=3), tf.image.decode_jpeg(img3, channels=3)\n",
        "    img1, img2, img3 = np.asarray(img1), np.asarray(img2), np.asarray(img3)\n",
        "    (x1, y1, w1, h1), (x2, y2, w2, h2), (x3, y3, w3, h3) = face_cascade.detectMultiScale(img1, 1.3, 5)[0], face_cascade.detectMultiScale(img2, 1.3, 5)[0], face_cascade.detectMultiScale(img3, 1.3, 5)[0]\n",
        "    img1 , img2, img3 = img1[y1:y1+h1, x1:x1+w1], img2[y2:y2+h2, x2:x2+w2], img3[y3:y3+h3, x3:x3+w3]\n",
        "    img1, img2, img3 = tf.image.resize(img1, (299, 299)), tf.image.resize(img2, (299, 299)), tf.image.resize(img3, (299, 299))\n",
        "    img1, img2, img3 = tf.keras.applications.inception_v3.preprocess_input(img1), tf.keras.applications.inception_v3.preprocess_input(img2), tf.keras.applications.inception_v3.preprocess_input(img3)\n",
        "    return np.array(img1, ndmin=4), np.array(img2, ndmin=4), np.array(img3, ndmin=4)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "data = preprocess_image_pair(pn_images[46])\n",
        "print(data[0].shape)\n",
        "print(data[1].shape)\n",
        "print(data[2].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiV60DSirYct"
      },
      "source": [
        "image_model = tf.keras.applications.InceptionV3(include_top=True, weights='imagenet')\n",
        "new_input = image_model.input\n",
        "hidden_layer = image_model.layers[-1].output\n",
        "\n",
        "image_features_extract_model = tf.keras.Model(new_input, hidden_layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3t5Iz6O9Obs"
      },
      "source": [
        "class SiameseNet(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, model):\n",
        "    super().__init__()\n",
        "    self.model = model\n",
        "\n",
        "  def call(self, feat):\n",
        "    feats = self.model(feat[0])\n",
        "    nfeats = self.model(feat[2])\n",
        "    pfeats = self.model(feat[1])\n",
        "    final = tf.stack([feats, pfeats, nfeats])\n",
        "    return tf.transpose(final, perm=[1,2,0])\n",
        "\n",
        "\n",
        "class TripletLoss(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, alpha):\n",
        "    self.alpha = alpha\n",
        "    super().__init__()\n",
        "\n",
        "  def call(self, features):\n",
        "    pos = K.sum(K.square(features[:,:,0] - features[:,:,1]))\n",
        "    neg = K.sum(K.square(features[:,:,0] - features[:,:,2]))\n",
        "    base_loss = pos - neg + self.alpha\n",
        "    return K.maximum(base_loss, 0.0)\n",
        "\n",
        "def identity_loss(y_true, y_pred):\n",
        "  return K.mean(y_pred)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ep5QYO9qTqoT"
      },
      "source": [
        "image_input = tf.keras.layers.Input(shape=(299,299,3), name='image_input')\n",
        "negative_input = tf.keras.layers.Input(shape=(299,299,3), name='negative_input')\n",
        "positive_input = tf.keras.layers.Input(shape=(299,299,3), name='positive_input')\n",
        "\n",
        "siamese = SiameseNet(image_features_extract_model)([image_input, positive_input, negative_input])\n",
        "loss = TripletLoss(alpha=1)(siamese)\n",
        "model = tf.keras.Model(inputs=[image_input, positive_input, negative_input], outputs=loss)\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(lr=1e-4), loss = identity_loss)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEu773wpTq-I"
      },
      "source": [
        "images, positives, negatives = [], [], []\n",
        "\n",
        "for pair in tqdm(pn_images[:500]):\n",
        "  try:\n",
        "    data = preprocess_image_pair(pair)\n",
        "    images.append(data[0])\n",
        "    negatives.append(data[2])\n",
        "    positives.append(data[1])\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "images = np.concatenate(images)\n",
        "positives = np.concatenate(positives)\n",
        "negatives = np.concatenate(negatives)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxMb2Fr8t3iB"
      },
      "source": [
        "images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFNg-VTdSd0G"
      },
      "source": [
        "def scheduler(epoch, lr):     # Reduces LR by a factor of 10 on each epoch\n",
        "  if epoch == 1:\n",
        "    return lr\n",
        "  return lr / 10\n",
        "\n",
        "callbacks = [\n",
        "  tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=0)\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tl0-GID40A8k"
      },
      "source": [
        "history = model.fit([images, positives, negatives], np.ones(images.shape[0]), batch_size=10, verbose=2, epochs=6, callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3Jsz1SSVmGe"
      },
      "source": [
        "print(history.history.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJk2-978nr3L"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('Loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-q6KuTInsFB"
      },
      "source": [
        "plt.plot(history.history['lr'])\n",
        "plt.title('Learning Rate')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxWUBj5JAbMH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}